import pandas as pdimport numpy as npimport pyaging as pyaimport osimport matplotlib.pyplot as pltimport seaborn as snsfrom scipy.stats import pearsonr, ttest_indfrom statsmodels.stats.multitest import multipletestsgeo_data_27k = [    'GSE27317',    'GSE41037',    'GSE38873',    'GSE15745',    'GSE32393',    'GSE25892',    'GSE20242',    'GSE22595',    'GSE37988',    'GSE17448',    'GSE36642',    'GSE26126',    'GSE34035',    'GSE28746',    'GSE20236',    'GSE19711',    'GSE37008',    'GSE36812',    'GSE34257',    'GSE38608',    'GSE38291',    'GSE36166',    'GSE63384',    'GSE59274',    'GSE57285',    'GSE56606',    'GSE49908',    'GSE49907',    'GSE49905',    'GSE49904']geo_data_450k = [    'GSE90124',    'GSE115797',    'GSE99624',    'GSE108213',    'GSE92767',    'GSE69176',    'GSE40360',    'GSE59157',    'GSE42861',    'GSE77241',    'GSE148000']array_express_27k = [    'E-GEOD-43256',    'E-GEOD-64940',    'E-MTAB-2344',    'E-GEOD-62867',    'E-GEOD-44763',    'E-GEOD-48988',    'E-GEOD-58119',    'E-GEOD-58045',    'E-GEOD-57484',    'E-GEOD-54211',    'E-GEOD-56342',    'E-GEOD-27044',    'E-GEOD-36194',    'E-GEOD-21232',    'E-GEOD-32867',    'E-GEOD-30759',    'E-GEOD-30758',    'E-GEOD-32396',    'E-GEOD-31979',    'E-MTAB-625',    'E-MTAB-487']array_express_450k = [    'E-MTAB-2372',    'E-GEOD-73832',    'E-GEOD-71678',    'E-GEOD-71245',    'E-GEOD-83334',    'E-GEOD-75248',    'E-GEOD-77955',    'E-GEOD-67705',    'E-GEOD-77445',    'E-GEOD-79056',    'E-GEOD-72556',    'E-GEOD-52068',    'E-GEOD-74738',    'E-GEOD-76105',    'E-GEOD-65638',    'E-GEOD-71955',    'E-GEOD-63106',    'E-GEOD-73377',    'E-GEOD-56515',    'E-GEOD-73103',    'E-GEOD-67024',    'E-GEOD-72338',    'E-GEOD-59457',    'E-GEOD-64511',    'E-GEOD-64495',    'E-GEOD-59509',    'E-GEOD-67444',    'E-GEOD-62219',    'E-GEOD-51954',    'E-GEOD-52588',    'E-GEOD-36054',    'E-GEOD-50660',    'E-GEOD-61259',    'E-GEOD-61258',    'E-GEOD-61257',    'E-GEOD-61454',    'E-GEOD-61380',    'E-GEOD-61107',    'E-GEOD-54690',    'E-GEOD-49149',    'E-GEOD-55438',    'E-GEOD-53740',    'E-GEOD-57767',    'E-GEOD-49064',    'E-GEOD-50759',    'E-GEOD-56553',    'E-GEOD-54399',    'E-GEOD-53162',    'E-GEOD-53128',    'E-GEOD-50498',    'E-GEOD-47513',    'E-GEOD-49393',    'E-GEOD-39004',    'E-GEOD-51388',    'E-GEOD-51032',    'E-GEOD-48325',    'E-GEOD-44712',    'E-GEOD-45461',    'E-GEOD-40279',    'E-GEOD-41169',    'E-GEOD-32149',    'E-GEOD-41826',    'E-GEOD-42700',    'E-GEOD-32146',    'E-GEOD-30870',    'E-GEOD-34639',    'E-GEOD-63347',    'E-GEOD-59592']tcga_all = [    'TGCA_LUSC',    'TGCA_THCA',    'TGCA_HNSC',    'TGCA_KIRC',    'TGCA_KIRP',    'TGCA_LUAD',    'TGCA_PRAD',    'TGCA_STAD',    'TGCA_COAD',    'TGCA_LIHC',    'TGCA_UCEC',    'TGCA_BRCA']cancer_data = [    'GSE32393',    'GSE37988',    'GSE26126',    'GSE63384',    'GSE59157',    'E-GEOD-32867',    'E-GEOD-30759',    'E-GEOD-31979',    'E-GEOD-77955',    'E-GEOD-52068',    'E-GEOD-49149',    'E-GEOD-39004']cancer_comparison = [    'GSE53051',]reliability = [    'GSE55763',]rejuvenation = [    'GSE142439',    'GSE116754',    'GSE65214',    'GSE44430',    'GSE45727',    'GSE30653',    'GSE37066',    'GSE30456',]senescence_analysis = [    'GSE91069',    'GSE100249']data_27k = np.concatenate([np.array(geo_data_27k), np.array(array_express_27k)])data_450k = np.concatenate([np.array(geo_data_450k), np.array(array_express_450k)])tcga_all = np.array(tcga_all)all_data = np.concatenate([data_27k, data_450k, tcga_all])# ------------------------# 1. Data Loading# ------------------------def load_data(cancer=False):    all_dfs = []    for filename in os.listdir("geo_data"):        if filename.endswith(".pkl") and filename.split('.')[0] in all_data:            if not cancer and filename.split('.')[0] in cancer_data:                continue            print(f"--- loading {filename} ---")            df = pd.read_pickle(os.path.join("geo_data", filename))            df["source_file"] = filename            all_dfs.append(df)    combined_df = pd.concat(all_dfs, ignore_index=False)    combined_df['female'] = (combined_df['gender'] == 'F').astype(int)    return combined_dfdef probe_agg(combined_df):    combined_df_probe = pya.pp.epicv2_probe_aggregation(combined_df)    combined_df_probe["chronological_age"] = combined_df_probe["age"]    return combined_df_probe.drop(columns=["age"])def to_adata(combined_df_probe):    return pya.pp.df_to_adata(combined_df_probe,                               metadata_cols=['gender', 'tissue_type', 'dataset', 'source_file', 'chronological_age'],                               imputer_strategy='knn')# ------------------------# 2. Clock Prediction + Residuals# ------------------------def predict_age(adata, models):    pya.pred.predict_age(adata, models)    return adatadef calculate_residuals(adata, models):    for model in models:        adata.obs[f"residual_{model}"] = adata.obs[model] - adata.obs["chronological_age"]    return adata# ------------------------# 3. Residual Labeling# ------------------------def get_residual_groups(adata, model_name):    residuals = adata.obs[model_name] - adata.obs['chronological_age']    upper_thresh = np.quantile(residuals, 0.80)    lower_thresh = np.quantile(residuals, 0.20)    return residuals, residuals > upper_thresh, residuals < lower_thresh# ------------------------# 4. Statistical Feature Selection# ------------------------def perform_ttests_on_cpgs(adata, acceleration_idx, deceleration_idx):    X = adata.X    feature_names = adata.var_names    X_acc = X[acceleration_idx, :]    X_dec = X[deceleration_idx, :]    t_stats = []    p_values = []    mean_diffs = []    abs_diffs = []    for i in range(X.shape[1]):        x1 = X_acc[:, i]        x2 = X_dec[:, i]        # T-test        t_stat, p = ttest_ind(x1, x2, equal_var=False)        t_stats.append(t_stat)        p_values.append(p)        # Effect size: mean difference        mean_diff = np.mean(x1) - np.mean(x2)        mean_diffs.append(mean_diff)        abs_diffs.append(np.abs(mean_diff))    # Adjust for multiple testing    _, pvals_corrected, _, _ = multipletests(p_values, alpha=0.05, method='fdr_bh')    # Create results dataframe    results = pd.DataFrame({        'CpG': feature_names,        't_stat': t_stats,        'p_value': p_values,        'p_adj': pvals_corrected,        'mean_diff': mean_diffs,        'abs_diff': abs_diffs    }).sort_values('p_adj')    return resultsdef filter_low_variance(adata, threshold=0.01):    """    Removes CpGs (features) with variance below the given threshold across samples.    Returns a filtered AnnData object and prints how many features were removed.    """    from sklearn.feature_selection import VarianceThreshold    print(f"Starting with {adata.shape[1]} features before variance filtering.")    selector = VarianceThreshold(threshold=threshold)    X_filtered = selector.fit_transform(adata.X)    selected_indices = selector.get_support(indices=True)    removed_count = adata.shape[1] - len(selected_indices)    print(f"Filtered out {removed_count} low-variance features (threshold = {threshold})")    adata_filtered = adata[:, selected_indices].copy()    return adata_filtereddef apply_statistical_tests(adata, labels):    """    Applies t-tests between two groups (labels should be binary: 0 and 1).    Returns DataFrame with t-stats, p-values, and FDR-adjusted p-values.    """    from scipy.stats import ttest_ind    group_1 = adata.X[labels == 1]    group_0 = adata.X[labels == 0]    t_stats, p_values = ttest_ind(group_1, group_0, axis=0, equal_var=False)    _, p_adj, _, _ = multipletests(p_values, alpha=0.05, method='fdr_bh')    results = pd.DataFrame({        'CpG': adata.var_names,        't_stat': t_stats,        'p_value': p_values,        'p_adj': p_adj    })    return results.sort_values("p_adj")def correlation_filter(df, threshold=0.85):    """    Efficient correlation-based feature filtering for high-dimensional CpG data.    """    print(f"Starting with {df.shape[1]} features.")    to_drop = set()    cols = df.columns.tolist()    for i in range(len(cols)):        if cols[i] in to_drop:            continue        for j in range(i + 1, len(cols)):            if cols[j] in to_drop:                continue            corr = np.corrcoef(df[cols[i]], df[cols[j]])[0, 1]            if abs(corr) > threshold:                to_drop.add(cols[j])        if i % 50 == 0:            print(f"Checked {i}/{len(cols)} CpGs...")    print(f"Filtered out {len(to_drop)} features due to correlation > {threshold}")    return df.drop(columns=list(to_drop))# ------------------------# 5. SHAP Modeling + Interpretation# ------------------------def train_model(X, y, model_type="xgboost"):    """    Trains a tree-based model (XGBoost or Random Forest) for classification.    Returns the trained model.    """    from sklearn.ensemble import RandomForestClassifier    import xgboost as xgb    if model_type == "xgboost":        model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')    elif model_type == "random_forest":        model = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)    else:        raise ValueError("Unsupported model type. Choose 'xgboost' or 'random_forest'.")    model.fit(X, y)    print(f"Trained {model_type} model on {X.shape[0]} samples and {X.shape[1]} features.")    return modeldef compute_shap(model, X):    """    Computes SHAP values for a tree-based model using TreeExplainer.    Returns SHAP values and explainer object.    """    import shap    explainer = shap.TreeExplainer(model)    shap_values = explainer.shap_values(X)    print("Computed SHAP values.")    return shap_values, explainerdef stratify_and_compare_shap(shap_values, group_labels, feature_names, top_n=20):    """    Computes and compares mean SHAP values across stratified groups.    Plots top features with highest SHAP differences between groups.    """    import pandas as pd    import matplotlib.pyplot as plt    # Create SHAP DataFrame    shap_df = pd.DataFrame(shap_values, columns=feature_names)    group_labels = group_labels.loc[adata_binary.obs.index]  # align index    shap_df['group'] = group_labels.reset_index(drop=True).values    # Compute mean SHAP values per group    group_means = shap_df.groupby('group').mean()    # Compute absolute differences between first two groups    if group_means.shape[0] < 2:        print("Need at least two groups to compare.")        return    diff = group_means.iloc[0] - group_means.iloc[1]    diff = diff.abs().sort_values(ascending=False)    top_features = diff.head(top_n).index.tolist()    # Plot    group_means[top_features].T.plot(kind='bar', figsize=(12, 6))    plt.title("Mean SHAP Values per Group (Top Differentiating Features)")    plt.ylabel("Mean SHAP Value")    plt.xticks(rotation=45, ha='right')    plt.tight_layout()    plt.show()# ------------------------# 7. Visualization# ------------------------def compute_group_methylation(adata, group_labels, cpg_list):    """    Computes mean methylation per group for selected CpG sites.    """    import pandas as pd    df = pd.DataFrame(adata[:, cpg_list].X, columns=cpg_list)    df['group'] = group_labels.reset_index(drop=True)    return df.groupby('group').mean()def plot_group_methylation(methylation_df, top_features=None, top_n=10):    """    Plots average methylation values per group for top N selected CpGs.    If top_features is provided, only those CpGs are considered.    """    import matplotlib.pyplot as plt    import pandas as pd    if top_features is not None:        # Ensure features exist in DataFrame and limit to top N        top_features = [cpg for cpg in top_features if cpg in methylation_df.columns][:top_n]        methylation_df = methylation_df[top_features]    else:        methylation_df = methylation_df.iloc[:, :top_n]    methylation_df.T.plot(kind='bar', figsize=(12, 6))    plt.title("Mean Methylation per Group (Top CpGs)")    plt.ylabel("Mean Beta Value")    plt.xlabel("CpG Site")    plt.xticks(rotation=90, ha='center')    plt.tight_layout()    plt.show()def plot_residual_distribution(adata, models):    residuals_df = adata.obs[[f"residual_{m}" for m in models]].melt(var_name="Model", value_name="Residual")    plt.figure(figsize=(10, 5))    sns.histplot(data=residuals_df, x="Residual", hue="Model", kde=True, bins=40, element="step", stat="density")    plt.title(f"Residual Distribution {models}")    plt.xlabel("Residual (Predicted - Chronological Age)")    plt.ylabel("Density")    plt.tight_layout()    plt.show()def plot_residuals_by_age(adata, models):    for model in models:        x = adata.obs['chronological_age']        y = adata.obs[f'residual_{model}']        r, _ = pearsonr(x, y)        plt.figure(figsize=(6, 6))        plt.scatter(x, y, alpha=0.7)        plt.plot(np.unique(x), np.poly1d(np.polyfit(x.astype(float), y.astype(float), 1))        (np.unique(x)), color='red')        plt.title(f"Residuals vs Age | {model} | R = {r:.3f}")        plt.xlabel("Chronological Age")        plt.ylabel("Residual")        plt.grid(True)        plt.tight_layout()        plt.show()def plot_acceleration_by_age(adata, models):    for model in models:        data = adata.obs.copy()        data = data[data[f'residual_{model}'].astype(float) > 0]        x = data['chronological_age']        y = data[f'residual_{model}']        r, _ = pearsonr(x, y)        plt.figure(figsize=(6, 6))        plt.scatter(x, y, alpha=0.7)        plt.plot(np.unique(x), np.poly1d(np.polyfit(x.astype(float), y.astype(float), 1))        (np.unique(x)), color='red')        plt.title(f"Acceleration vs Age | {model} | R = {r:.3f}")        plt.xlabel("Chronological Age")        plt.ylabel("Acceleration")        plt.grid(True)        plt.tight_layout()        plt.show()def plot_deceleration_by_age(adata, models):    for model in models:        data = adata.obs.copy()        data = data[data[f'residual_{model}'].astype(float) < 0]        x = data['chronological_age']        y = data[f'residual_{model}']        r, _ = pearsonr(x, y)        plt.figure(figsize=(6, 6))        plt.scatter(x, y, alpha=0.7)        plt.plot(            np.unique(x),            np.poly1d(np.polyfit(x.astype(float), y.astype(float), 1)) (np.unique(x)),            color='red')        plt.title(f"Deceleration vs Age | {model} | R = {r:.3f}")        plt.xlabel("Chronological Age")        plt.ylabel("Deceleration")        plt.grid(True)        plt.tight_layout()        plt.show()def plot_top_cpgs(adata, acc_idx, dec_idx, results, top_n=10):    # significant = results[(results['p_adj'] < 0.05) & (results['abs_diff'] > 0.1)]    top_results = results[results['p_adj'] < 0.05].head(top_n)    top_cpgs = top_results['CpG'].values    pvals = dict(zip(top_results['CpG'], top_results['p_value']))    padj = dict(zip(top_results['CpG'], top_results['p_adj']))    group_labels = np.where(acc_idx, 'Acceleration', np.where(dec_idx, 'Deceleration', 'Other'))    mask = acc_idx | dec_idx    X_plot = adata.X[mask][:, adata.var_names.isin(top_cpgs)]    groups = group_labels[mask]    df_plot = pd.DataFrame(X_plot, columns=adata.var_names[adata.var_names.isin(top_cpgs)])    df_plot['Group'] = groups    df_long = df_plot.melt(id_vars='Group', var_name='CpG', value_name='Methylation')    # Add both p-value and adjusted p-value to label    df_long['CpG_label'] = df_long['CpG'].apply(        lambda x: f"{x}"    )    print(df_long.groupby(['CpG_label', 'Group'])['Methylation'].mean().unstack())    # Violin plot    plt.figure(figsize=(16, 6))    sns.violinplot(data=df_long, x='CpG_label', y='Methylation', hue='Group', split=True)    plt.title('Top CpGs: Methylation in Acceleration vs Deceleration (Violin Plot)')    plt.xticks(rotation=45)    plt.tight_layout()    plt.show()    # Box plot    plt.figure(figsize=(16, 6))    sns.boxplot(data=df_long, x='CpG_label', y='Methylation', hue='Group')    plt.title('Top CpGs: Methylation in Acceleration vs Deceleration (Box Plot)')    plt.xticks(rotation=45)    plt.tight_layout()    plt.show()def plot_p_value_distribution(results):    plt.figure(figsize=(12, 5))    # Raw p-values    plt.subplot(1, 2, 1)    sns.histplot(results['p_value'], bins=50, kde=False, color='skyblue')    plt.title('Distribution of Raw p-values')    plt.xlabel('p-value')    plt.ylabel('CpG Count')    plt.grid(True)    # Adjusted p-values    plt.subplot(1, 2, 2)    sns.histplot(results['p_adj'], bins=50, kde=False, color='lightcoral')    plt.title('Distribution of Adjusted p-values (FDR)')    plt.xlabel('Adjusted p-value')    plt.ylabel('CpG Count')    plt.grid(True)    plt.tight_layout()    plt.show()def plot_enrichment_results(enrichment_results):    passdef plot_shap_summary(shap_values, X, feature_names):    """    Plots SHAP summary plot for feature importance.    """    import shap    shap.summary_plot(shap_values, X, feature_names=feature_names, show=True)def plot_shap_bar(shap_values, X, feature_names, top_n=20):    """    Plots SHAP bar plot of top N features.    """    import shap    shap.summary_plot(shap_values, X, feature_names=feature_names, plot_type="bar", max_display=top_n, show=True)def plot_signed_shap_bar(shap_values, feature_names, top_n=20):    """    Plots a bar chart of mean SHAP values (not abs) to show positive/negative direction.    """    import numpy as np    import matplotlib.pyplot as plt    shap_means = np.mean(shap_values, axis=0)    sorted_indices = np.argsort(shap_means)[-top_n:]    sorted_features = [feature_names[i] for i in sorted_indices]    sorted_values = shap_means[sorted_indices]    plt.figure(figsize=(10, 6))    bars = plt.barh(range(top_n), sorted_values, color=['red' if val > 0 else 'blue' for val in sorted_values])    plt.yticks(range(top_n), sorted_features)    plt.xlabel("Mean SHAP value")    plt.title("Signed SHAP Values (Positive vs Negative Impact)")    plt.axvline(0, color="black", linestyle="--")    plt.tight_layout()    plt.show()def save_filtered_features(df_filtered, filepath="filtered_cpgs.pkl"):    """    Saves the filtered DataFrame of CpGs to a pickle file.    """    df_filtered.to_pickle(filepath)    print(f"Filtered CpG DataFrame saved to {filepath}.")def load_filtered_features(filepath="filtered_cpgs.pkl"):    """    Loads the filtered CpG DataFrame from a pickle file.    """    import os    if os.path.exists(filepath):        print(f"Loading filtered CpGs from {filepath}.")        return pd.read_pickle(filepath)    else:        print(f"Filtered file {filepath} not found. Will recompute.")        return Nonedef ensure_top_features(df_filtered, ttest_results):    """    Ensures only CpGs from the t-test results are selected from the filtered DataFrame.    Returns filtered DataFrame and list of top features.    """    common = [cpg for cpg in ttest_results['CpG'] if cpg in df_filtered.columns]    return df_filtered[common], common# ------------------------# Main Pipeline Execution# ------------------------if __name__ == "__main__":    # Load and preprocess data    models = ["horvath2013"]    data = load_data()    combined_df = probe_agg(data)    adata = to_adata(combined_df)    adata = predict_age(adata, models)    adata = calculate_residuals(adata, models)    print("Defining residual groups.")    residuals, acc_idx, dec_idx = get_residual_groups(adata, "horvath2013")    print(f"Residual groups: acceleration = {acc_idx.sum()}, deceleration = {dec_idx.sum()}")    print("Filtering out low variance CpGs.")    adata_filtered = filter_low_variance(adata)    print("Creating binary labels for t-test.")    binary_labels = np.where(acc_idx, 1, np.where(dec_idx, 0, -1))    selected_indices = binary_labels != -1    adata_binary = adata_filtered[selected_indices, :]    labels = binary_labels[selected_indices]    print("Applying t-test.")    ttest_results = apply_statistical_tests(adata_binary, labels)    print("Reducing multicollinearity.")    df_cpgs = pd.DataFrame(adata_binary.X, columns=adata_binary.var_names)    df_filtered = load_filtered_features()    if df_filtered is None:        df_filtered = correlation_filter(df_cpgs[ttest_results['CpG']], threshold=0.85)        save_filtered_features(df_filtered)    df_filtered, top_features = ensure_top_features(df_filtered, ttest_results)    top_features = [f for f in top_features if f.startswith("cg")]    X = df_filtered[top_features].values    y = labels    model = train_model(X, y, model_type="xgboost")    shap_values, explainer = compute_shap(model, X)    print("\n===== SHAP Summary Plot =====")    plot_shap_summary(shap_values, X, feature_names=top_features)    print("\n===== Signed SHAP Bar Plot =====")    plot_signed_shap_bar(shap_values, top_features)    print("\n===== Define Age Bins =====")    age = adata_binary.obs["chronological_age"]    age_bins = pd.cut(age, bins=[0, 25, 40, 55, 75, 120],                      labels=["childâ€“young adult", "early adult", "midlife rise", "late-life drop", "oldest"],                      right=False)    print("\n===== Stratified SHAP Comparison by Age Group =====")    stratify_and_compare_shap(shap_values, age_bins, top_features)    print("\n===== Methylation Levels by Age Group =====")    methylation_by_age_bin = compute_group_methylation(adata_binary, age_bins, top_features)    plot_group_methylation(methylation_by_age_bin, top_features)    print("\n===== CpG Methylation Distributions in Acceleration vs Deceleration =====")    ttest_results = perform_ttests_on_cpgs(adata_binary, acc_idx[selected_indices], dec_idx[selected_indices])    plot_top_cpgs(adata_binary, acc_idx[selected_indices], dec_idx[selected_indices], ttest_results)